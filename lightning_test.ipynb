{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.models.convnext import LayerNorm2d\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import (Compose, RandomResizedCrop, \n",
    "                                    RandomHorizontalFlip, ColorJitter, \n",
    "                                    AutoAugment, InterpolationMode, v2, ToTensor)\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models.convnext import ConvNeXt_Tiny_Weights\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import PIL\n",
    "import seaborn as sn\n",
    "\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "from tqdm.auto import tqdm\n",
    "import time \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "shape = (224, 224)\n",
    "epochs=50\n",
    "num_classes=15\n",
    "batch_size=8\n",
    "learning_rate=5e-5\n",
    "weight_decay = 1e-8\n",
    "optimizer_momentum = (0.9, 0.999)\n",
    "scale_factor = 0.8 \n",
    "drop_path_rate = 0.1\n",
    "label_smoothing = 0.1\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvNeXtTiny(pl.LightningModule):\n",
    "    def __init__(self, epochs = epochs, learning_rate = learning_rate, scale_factor = scale_factor, drop_path_rate = drop_path_rate, num_classes=num_classes, label_smoothing = label_smoothing):\n",
    "        super(CustomConvNeXtTiny, self).__init__()\n",
    "        \n",
    "        # Carregar o modelo ConvNeXt-Tiny com pesos pré-treinados\n",
    "        self.model = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT, drop_path_rate=drop_path_rate)\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scale_factor = scale_factor\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "        # Definir as camadas sequenciais para classificação\n",
    "        self.sequential_layers = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.LayerNorm(768, eps=1e-6, elementwise_affine=True),\n",
    "            nn.Linear(in_features=768, out_features=num_classes, bias=True)\n",
    "        )\n",
    "        \n",
    "        # Substituir a camada classifier do modelo\n",
    "        self.model.classifier = self.sequential_layers\n",
    "        \n",
    "        # Métricas\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.train_accuracy(logits, labels)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.val_accuracy(logits, labels)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_step=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.test_accuracy(logits, labels)\n",
    "        self.log('test_accuracy', self.test_accuracy, on_step=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Prepare the list for optimizer param groups\n",
    "        param_groups = []\n",
    "\n",
    "        # Scale learning rate for each block in the model's features\n",
    "        for i, block in enumerate(self.model.features):\n",
    "            lr = self.learning_rate * (self.scale_factor ** i)\n",
    "            param_groups.append({'params': block.parameters(), 'lr': lr})\n",
    "\n",
    "        # Add classifier parameters with final scaled learning rate\n",
    "        classifier_lr = self.learning_rate * (self.scale_factor ** len(self.model.features))\n",
    "        param_groups.append({'params': self.model.classifier.parameters(), 'lr': classifier_lr})\n",
    "\n",
    "        # Define the optimizer with parameter groups\n",
    "        optimizer = torch.optim.Adam(param_groups)\n",
    "\n",
    "        # Define scheduler\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=self.epochs)  # Example with T_max=10\n",
    "\n",
    "        # Return both optimizer and scheduler\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',  # Step the scheduler per epoch\n",
    "                'monitor': 'val_loss',  # Optional, monitor val_loss (useful for other schedulers)\n",
    "                'frequency': 1,  # Apply the scheduler every epoch\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CustomImageModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_dir, test_dir,batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.image_transform = v2.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.Resize((224, 224), interpolation=PIL.Image.BILINEAR, antialias=False),\n",
    "            v2.ToDtype(torch.uint8, scale=True),\n",
    "\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomVerticalFlip(p=0.1),\n",
    "            v2.RandomErasing(p=0.25),\n",
    "            v2.RandAugment(num_ops=9, magnitude=5),\n",
    "\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Setup training, validation, and test datasets.\"\"\"\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            # Load entire dataset with transforms applied\n",
    "            entire_dataset = datasets.ImageFolder(root=self.train_dir, transform=self.image_transform)\n",
    "\n",
    "            # Split dataset into training and validation (80-20 split)\n",
    "            train_size = int(0.8 * len(entire_dataset))\n",
    "            val_size = len(entire_dataset) - train_size\n",
    "            self.train_ds, self.val_ds = random_split(entire_dataset, [train_size, val_size])\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_ds = datasets.ImageFolder(root=self.test_dir, transform=self.image_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Return the training data loader.\"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Return the validation data loader.\"\"\"\n",
    "        return DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Return the test data loader.\"\"\"\n",
    "        return DataLoader(\n",
    "            self.test_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"imagens/swedish/train\"\n",
    "test_dir = \"imagens/swedish/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = CustomImageModule(train_dir, test_dir, batch_size, num_workers)\n",
    "model = CustomConvNeXtTiny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomImageModule at 0x7240e14897f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.models.convnext as ConvNeXt\n",
    "from torchvision.models import ConvNeXt_Tiny_Weights\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from pytorch_lightning.utilities.types import TRAIN_DATALOADERS\n",
    "from torchmetrics import Accuracy\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/rodrigo/miniconda3/envs/mestrado/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type               | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model             | ConvNeXt           | 27.8 M | train\n",
      "1 | sequential_layers | Sequential         | 13.1 K | train\n",
      "2 | train_accuracy    | MulticlassAccuracy | 0      | train\n",
      "3 | val_accuracy      | MulticlassAccuracy | 0      | train\n",
      "4 | test_accuracy     | MulticlassAccuracy | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "27.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.8 M    Total params\n",
      "111.327   Total estimated model params size (MB)\n",
      "206       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a781110b684c10b9b6884a5a3bf806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f58f062a1c64709aedb2a627fd292ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b769a7629c243b8ba9adcb0c66622b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8031de8b7fc4aa1814496f6197786e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c308f94d96241f7849217b873ef2ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f509e347001b48a9b5dbf861bf0e607c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0023cfbe18a64cb79136f37a07b947bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac1ab368c5b481dac7d1fd9dd8acb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877bf93a104348ff99317f62e9f7073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c943c468d664f43b296bc30e541f5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f497eb98f0f44ec8572e2958a22d7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219bd0eff0b3423c8063bc8ab32d0483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8d8afb3ef84b3181a12f5fe21fef70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_accuracy_epoch      0.9777777791023254\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy_epoch': 0.9777777791023254}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie o Trainer e execute o treinamento\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1, precision='16-mixed', max_epochs=10)  # Ajuste o número de GPUs conforme necessário\n",
    "trainer.fit(model, data_module)\n",
    "trainer.test(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
