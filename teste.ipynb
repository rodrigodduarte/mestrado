{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "# Nome das classes (substitua pelos nomes das suas classes)\n",
    "classes = ['Classe 1', 'Classe 2', 'Classe 3', 'Classe 4', 'Classe 5', 'Classe 6', 'Classe 7']\n",
    "\n",
    "# Dados de exemplo: Precision, Recall, e F1 para cada modelo e classe\n",
    "# Cada linha representa uma métrica para um modelo\n",
    "# Ajuste esses valores para os seus resultados reais\n",
    "precision_data = [\n",
    "    [0.8, 0.7, 0.6, 0.9, 0.5, 0.4, 0.7],  # Modelo 1 (ResNet-101)\n",
    "    [0.75, 0.65, 0.55, 0.85, 0.6, 0.5, 0.65],  # Modelo 2 (ResNet-50)\n",
    "    [0.7, 0.6, 0.5, 0.8, 0.55, 0.45, 0.6],  # Modelo 3 (GoogleNet)\n",
    "    [0.65, 0.55, 0.45, 0.75, 0.5, 0.4, 0.55]  # Modelo 4 (VGG-16)\n",
    "]\n",
    "\n",
    "# Criação dos ângulos para o radar\n",
    "num_vars = len(classes)\n",
    "angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
    "angles += angles[:1]  # Fechar o gráfico\n",
    "\n",
    "# Função para criar gráficos de radar\n",
    "def plot_radar(data, title, labels):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Desenhar uma linha e preencher para cada modelo\n",
    "    for idx, values in enumerate(data):\n",
    "        values += values[:1]  # Fechar o gráfico\n",
    "        ax.plot(angles, values, linewidth=1, linestyle='solid', label=labels[idx])\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(classes, fontsize=10)\n",
    "    plt.title(title, size=15, color='black', y=1.1)\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "    plt.show()\n",
    "\n",
    "# Exibir gráficos de radar para precisão, recall e F1\n",
    "plot_radar(precision_data, 'Precision - Modelos', ['ResNet-101', 'ResNet-50', 'GoogleNet', 'VGG-16'])\n",
    "# Repita para os dados de recall e F1 se tiver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR, SequentialLR\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.models.convnext import (convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "                                         convnext_small, ConvNeXt_Small_Weights,\n",
    "                                         convnext_base, ConvNeXt_Base_Weights,\n",
    "                                         convnext_large, ConvNeXt_Large_Weights)\n",
    "from torchvision.models.swin_transformer import (swin_t, Swin_T_Weights,\n",
    "                                                 swin_s, Swin_S_Weights,\n",
    "                                                 swin_b, Swin_B_Weights)\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import config\n",
    "from compact_transform.src import cct_14_7x2_224, cct_14_7x2_384, cct_14_7x2_384_fl\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    def __init__(self, tmodel, epochs, learning_rate, scale_factor,\n",
    "                 drop_path_rate, num_classes, label_smoothing, optimizer_momentum):\n",
    "        \n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scale_factor = scale_factor\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.optimizer_momentum = optimizer_momentum\n",
    "        self.fn_loss = nn.CrossEntropyLoss(label_smoothing=self.label_smoothing)\n",
    "        \n",
    "        # Métricas\n",
    "        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "        self.model = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT, \n",
    "                                        drop_path_rate=self.drop_path_rate)\n",
    "        self.sequential_layers = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.LayerNorm(768, eps=1e-6, elementwise_affine=True),\n",
    "            nn.Linear(in_features=768, out_features=self.num_classes, bias=True)\n",
    "        )\n",
    "        self.model.classifier = self.sequential_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.train_accuracy(preds, labels)\n",
    "        \n",
    "        # Logar a perda e a acurácia\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_accuracy', self.train_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        # Retornar a perda para o processamento posterior\n",
    "        return {'loss': loss}\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        \n",
    "        # Calcular a precisão para validação\n",
    "        self.val_accuracy(preds, labels)\n",
    "        \n",
    "        # Logar a perda e a acurácia no conjunto de validação\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_accuracy', self.val_accuracy, prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        # Retornar a perda e a acurácia\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    # def on_train_epoch_end(self):\n",
    "    #     # Acessar a perda média do treino automaticamente através do logger\n",
    "    #     avg_loss = self.trainer.callback_metrics['train_loss']\n",
    "\n",
    "    #     # Imprimir a perda média de treino\n",
    "    #     print(f'Loss médio do treino na época: {avg_loss:.4f}')\n",
    "    \n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     # Acessar a perda média da validação automaticamente através do logger\n",
    "    #     avg_val_loss = self.trainer.callback_metrics['val_loss']\n",
    "\n",
    "    #     # Imprimir a perda média da validação\n",
    "    #     print(f'Loss médio da validação na época: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.test_accuracy(preds, labels)   \n",
    "        self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc_epoch\", self.test_accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Definir o otimizador com os grupos de parâmetros\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, betas = self.optimizer_momentum)\n",
    "\n",
    "        # Definir o scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "\n",
    "        # Retornar o otimizador e o scheduler\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',  # Step the scheduler per epoch\n",
    "                'monitor': 'val_loss',  # Optional, monitor val_loss (useful for other schedulers)\n",
    "                'frequency': 1,  # Apply the scheduler every epoch\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.train_accuracy(preds, labels)\n",
    "        \n",
    "        # Logar a perda e a acurácia\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_accuracy', self.train_accuracy, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        # Retornar a perda para o processamento posterior\n",
    "        return {'loss': loss}\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "        \n",
    "        # Calcular a precisão para validação\n",
    "        self.val_accuracy(preds, labels)\n",
    "        \n",
    "        # Logar a perda e a acurácia no conjunto de validação\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_accuracy', self.val_accuracy, prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        # Retornar a perda e a acurácia\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    # def on_train_epoch_end(self):\n",
    "    #     # Acessar a perda média do treino automaticamente através do logger\n",
    "    #     avg_loss = self.trainer.callback_metrics['train_loss']\n",
    "\n",
    "    #     # Imprimir a perda média de treino\n",
    "    #     print(f'Loss médio do treino na época: {avg_loss:.4f}')\n",
    "    \n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     # Acessar a perda média da validação automaticamente através do logger\n",
    "    #     avg_val_loss = self.trainer.callback_metrics['val_loss']\n",
    "\n",
    "    #     # Imprimir a perda média da validação\n",
    "    #     print(f'Loss médio da validação na época: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.forward(images)\n",
    "        loss = self.fn_loss(logits, labels)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        # Calcular a precisão\n",
    "        self.test_accuracy(preds, labels)   \n",
    "        self.log(\"test/loss_epoch\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"test/acc_epoch\", self.test_accuracy, on_step=False, on_epoch=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Definir o otimizador com os grupos de parâmetros\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, betas = self.optimizer_momentum)\n",
    "\n",
    "        # Definir o scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "\n",
    "        # Retornar o otimizador e o scheduler\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch',  # Step the scheduler per epoch\n",
    "                'monitor': 'val_loss',  # Optional, monitor val_loss (useful for other schedulers)\n",
    "                'frequency': 1,  # Apply the scheduler every epoch\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_hyperparameters(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        hyperparams = yaml.safe_load(file)  # Carregar o YAML\n",
    "    return hyperparams\n",
    "\n",
    "hyperparams = load_hyperparameters('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "\n",
    "model = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CustomModel\n",
    "\n",
    "import torch\n",
    "model = CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.randn(4, 5)       # tensor de forma (4, 5)\n",
    "features = torch.randn(4, 3)  # tensor de forma (4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "result = torch.cat((x, features), dim=1)\n",
    "print(result.shape)  # Saída: torch.Size([4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7456,  1.9984,  0.2324,  1.1532,  0.5112],\n",
      "        [ 0.8378, -0.0993, -0.2699, -0.6337,  0.7908],\n",
      "        [-0.4690,  1.0219, -0.8281,  0.5823, -0.1929],\n",
      "        [-1.0437,  0.0263,  2.1472,  0.4570,  0.2543]])\n",
      "tensor([[ 1.7456,  1.9984,  0.2324,  1.1532,  0.5112,  0.9984,  0.0297, -0.0805],\n",
      "        [ 0.8378, -0.0993, -0.2699, -0.6337,  0.7908,  0.7609,  0.4021,  1.9991],\n",
      "        [-0.4690,  1.0219, -0.8281,  0.5823, -0.1929,  0.1613, -0.6525,  0.5912],\n",
      "        [-1.0437,  0.0263,  2.1472,  0.4570,  0.2543,  0.0291, -1.1030, -0.4941]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
